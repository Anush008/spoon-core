{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is NeoFS?\n",
    "\n",
    "NeoFS is a distributed object storage service within the Neo blockchain ecosystem. It's a decentralized storage network that allows users to store and share data without relying on centralized service providers. NeoFS has the following features:\n",
    "\n",
    "1. **Decentralized Storage**: Data is distributed across network nodes with no single point of failure.\n",
    "2. **Data Ownership**: Users maintain complete control over their data.\n",
    "3. **Blockchain Integration**: Tightly integrated with the Neo blockchain, providing security and auditability.\n",
    "4. **Flexible Access Control**: Offers fine-grained access control policies.\n",
    "5. **Data Integrity**: Uses cryptographic techniques to ensure data integrity and authenticity.\n",
    "\n",
    "In this tutorial, we'll learn how to interact with NeoFS using Python, including creating containers, retrieving container lists, and performing signature operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "First, let's define some helper functions for encryption, encoding, and utility operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import binascii\n",
    "import httpx\n",
    "from base64 import b64decode, b64encode\n",
    "from hashlib import sha256\n",
    "\n",
    "# These libraries need to be installed: pip install pycryptodome ecdsa base58\n",
    "import base58\n",
    "from Crypto.PublicKey import ECC\n",
    "from Crypto.Hash import RIPEMD160\n",
    "import ecdsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions about cryptographic operations\n",
    "def wif_to_private_key(wif: str) -> bytes:\n",
    "    \"\"\"Convert from WIF format to raw private key\"\"\"\n",
    "    # Step 1: Decode WIF key using Base58\n",
    "    decoded = base58.b58decode(wif)\n",
    "    \n",
    "    # Step 2: Validate the length of decoded data\n",
    "    if len(decoded) != 38:\n",
    "        raise ValueError(\"Invalid WIF length\")\n",
    "    \n",
    "    # First byte is version, last 4 bytes are checksum\n",
    "    # version_byte = decoded[0]  # Typically 0x80 for Bitcoin mainnet\n",
    "    private_key_bytes = decoded[1:-5]  # Extract private key portion\n",
    "    checksum = decoded[-4:]  # Extract checksum portion\n",
    "    \n",
    "    # Step 3: Calculate expected checksum\n",
    "    hash1 = sha256(decoded[:-4]).digest()\n",
    "    hash2 = sha256(hash1).digest()\n",
    "    expected_checksum = hash2[:4]\n",
    "    \n",
    "    # Check if provided checksum matches calculated checksum\n",
    "    if checksum != expected_checksum:\n",
    "        raise ValueError(\"Invalid WIF checksum\")\n",
    "    \n",
    "    return private_key_bytes\n",
    "\n",
    "def hex_to_private_key(hex_str: str) -> bytes:\n",
    "    \"\"\"Convert from hex string to private key bytes\"\"\"\n",
    "    if hex_str.startswith('0x'):\n",
    "        hex_str = hex_str[2:]\n",
    "    return binascii.unhexlify(hex_str)\n",
    "\n",
    "def private_key_to_neo3_public_key_and_address(private_key: bytes) -> (str, str):\n",
    "    \"\"\"Generate NEO3 public key and address from private key\"\"\"\n",
    "    # Construct public key from private key using secp256r1 curve\n",
    "    public_key = ECC.construct(curve='secp256r1', d=int.from_bytes(private_key, 'big')).pointQ\n",
    "    x = public_key.x.to_bytes(32, 'big')\n",
    "    # Choose prefix based on y-coordinate parity (compressed format)\n",
    "    prefix = b'\\x02' if public_key.y % 2 == 0 else b'\\x03'\n",
    "    compressed_public_key = prefix + x\n",
    "    \n",
    "    # Generate verification script\n",
    "    verification_script = b'\\x0c\\x21' + compressed_public_key + b'\\x41\\x56\\xe7\\xb3\\x27'\n",
    "    \n",
    "    # Calculate script hash\n",
    "    ripemd160 = RIPEMD160.new()\n",
    "    ripemd160.update(sha256(verification_script).digest())\n",
    "    script_hash = ripemd160.digest()\n",
    "    \n",
    "    # Generate address (Neo address prefix is 0x35)\n",
    "    address = base58.b58encode_check(b'\\x35' + script_hash).decode('utf-8')\n",
    "    \n",
    "    return compressed_public_key.hex(), address\n",
    "\n",
    "def sign_message(private_key: bytes, message: str | bytes) -> bytes:\n",
    "    \"\"\"Sign a message using private key\"\"\"\n",
    "    assert len(private_key) == 32\n",
    "    if type(message) is str:\n",
    "        message: bytes = bytes.fromhex(message)\n",
    "    pk = ecdsa.SigningKey.from_string(private_key, curve=ecdsa.NIST256p, hashfunc=sha256)\n",
    "    signature: bytes = pk.sign_deterministic(message)\n",
    "    return signature\n",
    "\n",
    "def verify_message_signature(public_key: str | bytes, message: str | bytes, signature: bytes) -> bool:\n",
    "    \"\"\"Verify message signature\"\"\"\n",
    "    if type(public_key) is str:\n",
    "        public_key: bytes = bytes.fromhex(public_key)\n",
    "    assert len(public_key) == 33\n",
    "    assert public_key.startswith(b'\\x02') or public_key.startswith(b'\\x03')\n",
    "    if type(message) is str:\n",
    "        message: bytes = bytes.fromhex(message)\n",
    "    public_key: ecdsa.VerifyingKey = ecdsa.VerifyingKey.from_string(public_key, curve=ecdsa.NIST256p, hashfunc=sha256)\n",
    "    result = public_key.verify(signature, message)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions about data format conversions\n",
    "def num2VarInt(num: int) -> str:\n",
    "    \"\"\"Convert a number to variable-length integer hex string representation\"\"\"\n",
    "    if num < 0xfd:\n",
    "        return num2hexstring(num)\n",
    "    elif num <= 0xffff:\n",
    "        # uint16\n",
    "        return \"fd\" + num2hexstring(num, 2, True)\n",
    "    elif num <= 0xffffffff:\n",
    "        # uint32\n",
    "        return \"fe\" + num2hexstring(num, 4, True)\n",
    "    else:\n",
    "        # uint64\n",
    "        return \"ff\" + num2hexstring(num, 8, True)\n",
    "\n",
    "def num2hexstring(num: int, size: int = 1, little_endian=False) -> str:\n",
    "    \"\"\"Convert a number to a hex string\"\"\"\n",
    "    if not isinstance(num, int):\n",
    "        raise TypeError(f\"num2hexstring expected a number but got {type(num)}.\")\n",
    "    if num < 0:\n",
    "        raise ValueError(f\"num2hexstring expected a positive integer but got {num}.\")\n",
    "    if size % 1 != 0:\n",
    "        raise ValueError(f\"num2hexstring expected a positive integer but got {num}.\")\n",
    "    if num > 2 ** 53 - 1:\n",
    "        raise ValueError(f\"num2hexstring expected a safe integer but got {num}.\")\n",
    "    \n",
    "    size *= 2\n",
    "    hexstring = hex(num)[2:]\n",
    "    hexstring = hexstring.zfill(size)\n",
    "    \n",
    "    if little_endian:\n",
    "        hexstring = reverse_hex(hexstring)\n",
    "    return hexstring\n",
    "\n",
    "def reverse_hex(hexstring: str) -> str:\n",
    "    \"\"\"Reverse a hex string (reverse by byte pairs)\"\"\"\n",
    "    return ''.join(reversed([hexstring[i:i + 2] for i in range(0, len(hexstring), 2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Configuration\n",
    "\n",
    "In NeoFS, all operations require signing with a Neo wallet's private key to verify identity. Here, we'll start with a WIF (Wallet Import Format) private key and obtain the corresponding public key and address.\n",
    "\n",
    "**Note**: Always protect your private key and never expose it in public or insecure environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up private key - Replace with your own private key in actual use\n",
    "PRIVATE_KEY_WIF = \"\"  # Enter your WIF format private key here\n",
    "\n",
    "# Convert from WIF format to raw private key\n",
    "private_key = wif_to_private_key(PRIVATE_KEY_WIF)\n",
    "\n",
    "# Get corresponding public key and NEO3 address\n",
    "public_key, address = private_key_to_neo3_public_key_and_address(private_key)\n",
    "\n",
    "# Set up the base URL for the NeoFS gateway\n",
    "BASE_URL = 'https://rest.t5.fs.neo.org/v1/'  # This is a testnet URL, use the appropriate URL for production\n",
    "\n",
    "# Create an HTTP client\n",
    "httpx_client = httpx.Client(base_url=BASE_URL, headers={\"Content-Type\": \"application/json\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Creating and Retrieving Containers\n",
    "\n",
    "In NeoFS, all data is stored in containers. Containers are similar to \"buckets\" or \"folders\" in traditional cloud storage, defining storage policies and access control rules for data.\n",
    "\n",
    "Below we'll demonstrate how to create new containers and then query containers owned by the current user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Creating an Authentication Token\n",
    "\n",
    "Before creating a container, we need to obtain an authentication token. This is how permission control is implemented in NeoFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up authentication request headers\n",
    "auth_header = {\n",
    "    'X-Bearer-Owner-Id': address,       # Token owner's address\n",
    "    'X-Bearer-Lifetime': \"10000\",       # Token validity period (seconds)\n",
    "    'X-Bearer-For-All-Users': \"false\",  # Whether valid for all users\n",
    "}\n",
    "\n",
    "# Set up authentication content - Define token permissions\n",
    "auth_content = [\n",
    "    {\"name\":\"my-bearer-token\",\"object\":[{\"action\":\"ALLOW\",\"filters\":[],\"operation\":\"GET\",\"targets\":[{\"keys\":[],\"role\":\"OTHERS\"}]}]},\n",
    "    {\"container\":{\"verb\":\"PUT\"},\"name\":\"my token\"}\n",
    "]\n",
    "\n",
    "# Send authentication request\n",
    "try:\n",
    "    auth_resp = httpx_client.post('auth', \n",
    "                                  headers=auth_header, \n",
    "                                  content=json.dumps(auth_content)).json()\n",
    "    \n",
    "    # Decode and sign tokens\n",
    "    for t in auth_resp:\n",
    "        t[\"decoded_token\"] = b64decode(t[\"token\"])\n",
    "    \n",
    "    for t in auth_resp:\n",
    "        t[\"signed_token\"] = sign_message(private_key, t[\"decoded_token\"]).hex()\n",
    "    \n",
    "    # Verify signatures\n",
    "    for t in auth_resp:\n",
    "        assert verify_message_signature(public_key, t[\"decoded_token\"], bytes.fromhex(t[\"signed_token\"]))\n",
    "    \n",
    "    print(\"Authentication token created successfully:\")\n",
    "    print(auth_resp)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create authentication token: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Creating a New Container\n",
    "\n",
    "Now that we have an authentication token, we can use it to create a new container. Container creation requires a signature, so we need to prepare the signature data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the second token (for container creation)\n",
    "msg = auth_resp[1]['token']\n",
    "\n",
    "# Generate random salt (for increased security)\n",
    "random_salt = os.urandom(16).hex()  # Generate random salt\n",
    "\n",
    "# Prepare parameters and serialize\n",
    "parameter_hex_string = (random_salt + msg).encode().hex()\n",
    "assert len(parameter_hex_string) % 2 == 0  # Ensure even length\n",
    "length_hex = num2VarInt(len(parameter_hex_string) // 2)\n",
    "concatenated_string = length_hex + parameter_hex_string\n",
    "serialized_transaction = '010001f0' + concatenated_string + '0000'  # Specific format for transaction serialization\n",
    "\n",
    "# Sign transaction data\n",
    "signature = sign_message(private_key, serialized_transaction)\n",
    "assert verify_message_signature(public_key, serialized_transaction, signature)\n",
    "signature_hex_str = signature.hex()\n",
    "\n",
    "# Set request headers\n",
    "httpx_client.headers.update({\"Authorization\": f\"Bearer {auth_resp[1]['token']}\"})\n",
    "bearer_header = {\n",
    "    'X-Bearer-Owner-Id': address,                     # Owner address\n",
    "    'X-Bearer-Signature': signature_hex_str + random_salt,  # Signature + random salt\n",
    "    'X-Bearer-Signature-Key': public_key,              # Public key\n",
    "}\n",
    "\n",
    "# Create container\n",
    "try:\n",
    "    create_container_resp = httpx_client.put(\n",
    "        'containers?walletConnect=true&name-scope-global=true',  # API endpoint and parameters\n",
    "        headers=bearer_header,\n",
    "        content=json.dumps(\n",
    "            {\n",
    "                \"basicAcl\": \"public-read-write\",     # Access control level\n",
    "                \"containerName\": \"MyFirstContainer\",  # Container name\n",
    "                \"placementPolicy\": \"REP 3\"           # Replication policy: maintain 3 copies\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(f\"Container creation response: {create_container_resp.json()}\")\n",
    "    \n",
    "    # Retrieve container list again to see newly created container\n",
    "    list_container_resp = httpx_client.get(f'containers?ownerId={address}')\n",
    "    print(f\"\\nUpdated container list: {list_container_resp.json()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to create container: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Retrieving the Current User's Container List\n",
    "\n",
    "Now that we've created a container, let's see how to retrieve a list of all containers owned by the current user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all containers owned by current user\n",
    "try:\n",
    "    my_containers = httpx_client.get(f'containers?ownerId={address}').json()\n",
    "    print(f'My container list: {my_containers}')\n",
    "except Exception as e:\n",
    "    print(f\"Failed to retrieve container list: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Signature Operations\n",
    "\n",
    "In NeoFS, many operations require signatures to verify identity and authorization. The example below demonstrates how to sign a simple message (\"hello\"). This can be used as a test to verify that your key setup is correct, and to understand the signature mechanism in NeoFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display public key and address\n",
    "print(f\"Public key: {public_key}\")\n",
    "print(f\"Address: {address}\")\n",
    "print()\n",
    "\n",
    "# Message to sign\n",
    "msg = 'hello'\n",
    "\n",
    "# Use a fixed random salt for verification and testing\n",
    "# In production, use os.urandom(16).hex() to generate a random salt\n",
    "random_salt = '2b62f24c77ec30bac716b116651b9d23'  \n",
    "\n",
    "# Prepare parameters and serialize - similar to container creation process\n",
    "parameter_hex_string = (random_salt + msg).encode().hex()\n",
    "assert len(parameter_hex_string) % 2 == 0\n",
    "length_hex = num2VarInt(len(parameter_hex_string) // 2)\n",
    "concatenated_string = length_hex + parameter_hex_string\n",
    "serialized_transaction = '010001f0' + concatenated_string + '0000'\n",
    "print(f\"Serialized transaction: {serialized_transaction}\")\n",
    "print()\n",
    "\n",
    "# Sign transaction data\n",
    "signature = sign_message(private_key, serialized_transaction)\n",
    "\n",
    "# Output results\n",
    "print(f\"Random salt: {random_salt}\")\n",
    "print(f\"Signature: {signature.hex()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: File Operations in NeoFS\n",
    "\n",
    "After setting up a container in NeoFS, we can now perform key file operations such as uploading, downloading, and searching for files. These operations are essential for utilizing NeoFS as a decentralized storage system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Uploading Files to NeoFS\n",
    "\n",
    "To upload files to NeoFS, we first need to create an authentication token specifically for upload operations, then sign the upload request and send the file data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_upload_token(client, private_key, public_key, address, container_id):\n",
    "    \"\"\"\n",
    "    Create a token for uploading files\n",
    "    \n",
    "    Args:\n",
    "        client: Configured HTTPX client\n",
    "        private_key: Private key bytes\n",
    "        public_key: Public key hex string\n",
    "        address: Neo address\n",
    "        container_id: Container ID to upload to\n",
    "        \n",
    "    Returns:\n",
    "        dict: Auth token information\n",
    "    \"\"\"\n",
    "    auth_header = {\n",
    "        'X-Bearer-Owner-Id': address,\n",
    "        'X-Bearer-Lifetime': \"10000\",\n",
    "        'X-Bearer-For-All-Users': \"false\",\n",
    "    }\n",
    "    \n",
    "    auth_content = [\n",
    "        {\n",
    "            \"name\": \"upload-token\",\n",
    "            \"object\": [\n",
    "                {\n",
    "                    \"action\": \"ALLOW\",\n",
    "                    \"filters\": [],\n",
    "                    \"operation\": \"PUT\",\n",
    "                    \"targets\": [{\"keys\": [], \"role\": \"OTHERS\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    auth_resp = client.post('auth', headers=auth_header, content=json.dumps(auth_content), timeout=180).json()\n",
    "    \n",
    "    # Process and sign token\n",
    "    for t in auth_resp:\n",
    "        t[\"decoded_token\"] = b64decode(t[\"token\"])\n",
    "    for t in auth_resp:\n",
    "        t[\"signed_token\"] = sign_message(private_key, t[\"decoded_token\"]).hex()\n",
    "    for t in auth_resp:\n",
    "        assert verify_message_signature(public_key, t[\"decoded_token\"], bytes.fromhex(t[\"signed_token\"]))\n",
    "    \n",
    "    return auth_resp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(client, private_key, public_key, address, container_id, file_path, attributes=None, expiration=None):\n",
    "    \"\"\"\n",
    "    Upload a file to NeoFS\n",
    "    \n",
    "    Args:\n",
    "        client: Configured HTTPX client\n",
    "        private_key: Private key bytes\n",
    "        public_key: Public key hex string\n",
    "        address: Neo address\n",
    "        container_id: Container ID to upload to\n",
    "        file_path: Path to file to upload\n",
    "        attributes: Optional attributes for the file\n",
    "        expiration: Optional expiration time (RFC3339 format, timestamp, or duration)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Upload response containing object ID\n",
    "    \"\"\"\n",
    "    # Create token for upload operation\n",
    "    upload_token = create_upload_token(client, private_key, public_key, address, container_id)\n",
    "    \n",
    "    # Prepare for signature\n",
    "    msg = upload_token['token']\n",
    "    random_salt = os.urandom(16).hex()\n",
    "    parameter_hex_string = (random_salt + msg).encode().hex()\n",
    "    assert len(parameter_hex_string) % 2 == 0\n",
    "    length_hex = num2VarInt(len(parameter_hex_string) // 2)\n",
    "    concatenated_string = length_hex + parameter_hex_string\n",
    "    serialized_transaction = '010001f0' + concatenated_string + '0000'\n",
    "    signature = sign_message(private_key, serialized_transaction)\n",
    "    assert verify_message_signature(public_key, serialized_transaction, signature)\n",
    "    \n",
    "    # The API requires hex-encoded signature\n",
    "    signature_hex_str = signature.hex()\n",
    "    \n",
    "    # Update client headers with auth token\n",
    "    client.headers.update({\"Authorization\": f\"Bearer {upload_token['token']}\"})\n",
    "    \n",
    "    # Set up headers for the upload request\n",
    "    upload_headers = {\n",
    "        'X-Bearer-Signature': signature_hex_str + random_salt, # Include random salt with signature\n",
    "        'X-Bearer-Signature-Key': public_key,\n",
    "        'Content-Type': 'application/octet-stream',\n",
    "    }\n",
    "    \n",
    "    # Handle attributes\n",
    "    if attributes is None:\n",
    "        attributes = {}\n",
    "    \n",
    "    # Add filename as attribute if not provided\n",
    "    if 'FileName' not in attributes:\n",
    "        attributes['FileName'] = os.path.basename(file_path)\n",
    "    print(attributes['FileName'])\n",
    "    # Convert attributes to JSON and add to headers\n",
    "    upload_headers['X-Attributes'] = json.dumps(attributes)\n",
    "    \n",
    "    # Handle expiration if provided\n",
    "    if expiration:\n",
    "        if expiration.endswith('Z') or '+' in expiration or '-' in expiration:\n",
    "            # Assume RFC3339 format\n",
    "            upload_headers['X-Neofs-Expiration-RFC3339'] = expiration\n",
    "        elif expiration.endswith('s') or 'h' in expiration or 'm' in expiration:\n",
    "            # Assume duration format\n",
    "            upload_headers['X-Neofs-Expiration-Duration'] = expiration\n",
    "        else:\n",
    "            # Assume timestamp\n",
    "            upload_headers['X-Neofs-Expiration-Timestamp'] = expiration\n",
    "    \n",
    "    # Read file content\n",
    "    with open(file_path, 'rb') as f:\n",
    "        file_content = f.read()\n",
    "    \n",
    "    # Upload file\n",
    "    upload_resp = client.post(\n",
    "        f'objects/{container_id}?walletConnect=true',\n",
    "        headers=upload_headers,\n",
    "        content=file_content,\n",
    "        timeout=180\n",
    "    )\n",
    "    \n",
    "    return upload_resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these functions to upload a file to our container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Upload a file to NeoFS\n",
    "# First, let's create a simple text file\n",
    "with open(\"example.txt\", \"w\") as f:\n",
    "    f.write(\"Hello NeoFS! This is a test file for our tutorial.\")\n",
    "\n",
    "# Now upload the file to our container\n",
    "try:\n",
    "    # Get the first container ID from our list\n",
    "    container_id = my_containers['containers'][0]['containerId']\n",
    "    \n",
    "    # Upload with custom attributes and 24-hour expiration\n",
    "    upload_response = upload_file(\n",
    "        httpx_client, \n",
    "        private_key, \n",
    "        public_key, \n",
    "        address, \n",
    "        container_id, \n",
    "        \"example.txt\", \n",
    "        attributes={\"Description\": \"Test file for NeoFS tutorial\"},\n",
    "        expiration=\"24h\"\n",
    "    )\n",
    "    \n",
    "    print(f\"File uploaded successfully: {upload_response}\")\n",
    "    \n",
    "    # Store the object ID for later use\n",
    "    object_id = upload_response[\"object_id\"]\n",
    "except Exception as e:\n",
    "    print(f\"Upload failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Downloading Files from NeoFS\n",
    "\n",
    "Once files are uploaded to NeoFS, you can download them using their container ID and object ID. Similar to uploads, we need to create an authentication token for download operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_download_token(client, private_key, public_key, address, container_id, object_id=None):\n",
    "    \"\"\"\n",
    "    Create a token for downloading files\n",
    "    \n",
    "    Args:\n",
    "        client: Configured HTTPX client\n",
    "        private_key: Private key bytes\n",
    "        public_key: Public key hex string\n",
    "        address: Neo address\n",
    "        container_id: Container ID to download from\n",
    "        object_id: Optional specific object ID to download\n",
    "        \n",
    "    Returns:\n",
    "        dict: Auth token information\n",
    "    \"\"\"\n",
    "    auth_header = {\n",
    "        'X-Bearer-Owner-Id': address,\n",
    "        'X-Bearer-Lifetime': \"10000\",\n",
    "        'X-Bearer-For-All-Users': \"false\",\n",
    "    }\n",
    "    \n",
    "    # Create a more generic token similar to upload token\n",
    "    auth_content = [\n",
    "        {\n",
    "            \"name\": \"download-token\",\n",
    "            \"object\": [\n",
    "                {\n",
    "                    \"action\": \"ALLOW\",\n",
    "                    \"filters\": [],\n",
    "                    \"operation\": \"GET\",\n",
    "                    \"targets\": [{\"keys\": [], \"role\": \"OTHERS\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    auth_resp = client.post('auth', headers=auth_header, content=json.dumps(auth_content), timeout=180).json()\n",
    "    \n",
    "    # Process and sign token\n",
    "    for t in auth_resp:\n",
    "        t[\"decoded_token\"] = b64decode(t[\"token\"])\n",
    "    for t in auth_resp:\n",
    "        t[\"signed_token\"] = sign_message(private_key, t[\"decoded_token\"]).hex()\n",
    "    for t in auth_resp:\n",
    "        assert verify_message_signature(public_key, t[\"decoded_token\"], bytes.fromhex(t[\"signed_token\"]))\n",
    "    \n",
    "    return auth_resp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(client, private_key, public_key, address, container_id, object_id, output_path=None, range_header=None, force_download=False):\n",
    "    \"\"\"\n",
    "    Download a file from NeoFS\n",
    "    \n",
    "    Args:\n",
    "        client: Configured HTTPX client\n",
    "        private_key: Private key bytes\n",
    "        public_key: Public key hex string\n",
    "        address: Neo address\n",
    "        container_id: Container ID to download from\n",
    "        object_id: Object ID to download\n",
    "        output_path: Path to save downloaded file\n",
    "        range_header: Optional Range header value to request specific bytes\n",
    "        force_download: Whether to use the download query param to force browser download\n",
    "        \n",
    "    Returns:\n",
    "        bytes: File content if output_path is None, otherwise saves to file\n",
    "    \"\"\"\n",
    "    # Create token for download operation\n",
    "    download_token = create_download_token(client, private_key, public_key, address, container_id)\n",
    "    \n",
    "    # Prepare for signature\n",
    "    msg = download_token['token']\n",
    "    random_salt = os.urandom(16).hex()\n",
    "    parameter_hex_string = (random_salt + msg).encode().hex()\n",
    "    assert len(parameter_hex_string) % 2 == 0\n",
    "    length_hex = num2VarInt(len(parameter_hex_string) // 2)\n",
    "    concatenated_string = length_hex + parameter_hex_string\n",
    "    serialized_transaction = '010001f0' + concatenated_string + '0000'\n",
    "    signature = sign_message(private_key, serialized_transaction)\n",
    "    assert verify_message_signature(public_key, serialized_transaction, signature)\n",
    "    \n",
    "    # The API requires hex-encoded signature\n",
    "    signature_hex_str = signature.hex()\n",
    "    \n",
    "    # Update client headers with auth token\n",
    "    client.headers.update({\"Authorization\": f\"Bearer {download_token['token']}\"})\n",
    "    \n",
    "    download_headers = {\n",
    "        'X-Bearer-Signature': signature_hex_str + random_salt, # Include random salt with signature\n",
    "        'X-Bearer-Signature-Key': public_key,\n",
    "    }\n",
    "    \n",
    "    # Add Range header if specified\n",
    "    if range_header:\n",
    "        download_headers['Range'] = range_header\n",
    "    \n",
    "    # Construct URL with query parameters if needed\n",
    "    download_url = f'objects/{container_id}/by_id/{object_id}'\n",
    "    query_params = []\n",
    "    \n",
    "    query_params.append('walletConnect=true')\n",
    "    \n",
    "    if force_download:\n",
    "        query_params.append('download=true')\n",
    "    \n",
    "    if query_params:\n",
    "        download_url += '?' + '&'.join(query_params)\n",
    "    \n",
    "    # Download file\n",
    "    download_resp = client.get(\n",
    "        download_url,\n",
    "        headers=download_headers\n",
    "    )\n",
    "    \n",
    "    # Handle response\n",
    "    if download_resp.status_code != 200:\n",
    "        raise Exception(f\"Download failed with status code {download_resp.status_code}: {download_resp.text}\")\n",
    "    \n",
    "    content = download_resp.content\n",
    "    \n",
    "    # Extract file attributes if present\n",
    "    attributes = {}\n",
    "    if 'X-Attributes' in download_resp.headers:\n",
    "        try:\n",
    "            attributes = json.loads(download_resp.headers['X-Attributes'])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if output_path:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        return {\n",
    "            \"message\": f\"File saved to {output_path}\",\n",
    "            \"attributes\": attributes\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"content\": content,\n",
    "            \"attributes\": attributes\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the file we just uploaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Download the file\n",
    "    download_response = download_file(\n",
    "        httpx_client, \n",
    "        private_key, \n",
    "        public_key, \n",
    "        address, \n",
    "        container_id, \n",
    "        object_id, \n",
    "        output_path=\"downloaded_document.txt\",  # Assuming it's a text file\n",
    "        force_download=True\n",
    "    )\n",
    "    \n",
    "    print(f\"File downloaded successfully: {download_response}\")\n",
    "    \n",
    "    # Alternative implementation using scikit-learn\n",
    "    def process_and_vectorize_document_sklearn(file_path, chunk_size=1000, chunk_overlap=200):\n",
    "        \"\"\"\n",
    "        Process a downloaded document using scikit-learn for vectorization\n",
    "        \n",
    "        Args:\n",
    "            file_path: Path to the downloaded file\n",
    "            chunk_size: Size of text chunks for splitting\n",
    "            chunk_overlap: Overlap between chunks\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import numpy as np\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        import pickle\n",
    "        \n",
    "        # Simple text chunking function\n",
    "        def chunk_text(text, chunk_size, overlap):\n",
    "            chunks = []\n",
    "            start = 0\n",
    "            while start < len(text):\n",
    "                end = min(start + chunk_size, len(text))\n",
    "                chunks.append(text[start:end])\n",
    "                start += chunk_size - overlap\n",
    "            return chunks\n",
    "        \n",
    "        # Read the content of the file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        # Split text into chunks\n",
    "        chunks = chunk_text(text, chunk_size, chunk_overlap)\n",
    "        print(f\"Split document into {len(chunks)} chunks\")\n",
    "        \n",
    "        # Use TF-IDF to vectorize the text\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectors = vectorizer.fit_transform(chunks)\n",
    "        \n",
    "        # Save the chunks and vectors for later use\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(\"./vector_db\", exist_ok=True)\n",
    "        \n",
    "        # Save chunks to a file\n",
    "        with open(\"./vector_db/chunks.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            for chunk in chunks:\n",
    "                f.write(chunk + \"\\n===CHUNK_SEPARATOR===\\n\")\n",
    "        \n",
    "        # Save vectors using numpy\n",
    "        np.save(\"./vector_db/vectors.npy\", vectors.toarray())\n",
    "        \n",
    "        # Save vocabulary\n",
    "        with open(\"./vector_db/vectorizer.pkl\", \"wb\") as f:\n",
    "            pickle.dump(vectorizer, f)\n",
    "        \n",
    "        print(\"Document vectorized and stored in ./vector_db\")\n",
    "        \n",
    "        # Create a search function\n",
    "        def similarity_search(query, k=3):\n",
    "            # Vectorize the query\n",
    "            query_vector = vectorizer.transform([query])\n",
    "            \n",
    "            # Calculate similarity scores (cosine similarity)\n",
    "            from sklearn.metrics.pairwise import cosine_similarity\n",
    "            similarities = cosine_similarity(query_vector, vectors).flatten()\n",
    "            \n",
    "            # Get indices of top k results\n",
    "            top_indices = similarities.argsort()[-k:][::-1]\n",
    "            \n",
    "            # Create document-like objects with a page_content attribute\n",
    "            class Document:\n",
    "                def __init__(self, content):\n",
    "                    self.page_content = content\n",
    "            \n",
    "            # Return results\n",
    "            results = []\n",
    "            for idx in top_indices:\n",
    "                results.append(Document(chunks[idx]))\n",
    "            \n",
    "            return results\n",
    "        \n",
    "        # Return a database-like object with a similarity_search method\n",
    "        class VectorDB:\n",
    "            def __init__(self, search_func):\n",
    "                self.similarity_search = search_func\n",
    "        \n",
    "        return VectorDB(similarity_search)\n",
    "    \n",
    "    # Now process and vectorize the document\n",
    "    vectordb = process_and_vectorize_document_sklearn(\"downloaded_document.txt\")\n",
    "    \n",
    "    # Example of how to search the vector database\n",
    "    query = \"Your search query here\"\n",
    "    results = vectordb.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"Search results for '{query}':\")\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"Result {i+1}:\\n{doc.page_content}\\n\")\n",
    "        \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"Process failed: {e}\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Searching for Files in NeoFS\n",
    "\n",
    "NeoFS provides search functionality to find files based on their attributes. This is particularly useful when you have many files and need to find specific ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_token(client, private_key, public_key, address, container_id):\n",
    "    \"\"\"\n",
    "    Create a token for searching files\n",
    "    \n",
    "    Args:\n",
    "        client: Configured HTTPX client\n",
    "        private_key: Private key bytes\n",
    "        public_key: Public key hex string\n",
    "        address: Neo address\n",
    "        container_id: Container ID to search in\n",
    "        \n",
    "    Returns:\n",
    "        dict: Auth token information\n",
    "    \"\"\"\n",
    "    auth_header = {\n",
    "        'X-Bearer-Owner-Id': address,\n",
    "        'X-Bearer-Lifetime': \"10000\",\n",
    "        'X-Bearer-For-All-Users': \"false\",\n",
    "    }\n",
    "    \n",
    "    auth_content = [\n",
    "        {\n",
    "            \"name\": \"search-token\",\n",
    "            \"object\": [\n",
    "                {\n",
    "                    \"action\": \"ALLOW\",\n",
    "                    \"filters\": [],\n",
    "                    \"operation\": \"SEARCH\",\n",
    "                    \"targets\": [{\"keys\": [], \"role\": \"OTHERS\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    auth_resp = client.post('auth', headers=auth_header, content=json.dumps(auth_content), timeout=180).json()\n",
    "    \n",
    "    # Process and sign token\n",
    "    for t in auth_resp:\n",
    "        t[\"decoded_token\"] = b64decode(t[\"token\"])\n",
    "    for t in auth_resp:\n",
    "        t[\"signed_token\"] = sign_message(private_key, t[\"decoded_token\"]).hex()\n",
    "    for t in auth_resp:\n",
    "        assert verify_message_signature(public_key, t[\"decoded_token\"], bytes.fromhex(t[\"signed_token\"]))\n",
    "    \n",
    "    return auth_resp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_files(client, private_key, public_key, address, container_id, filters, offset=0, limit=100):\n",
    "    \"\"\"\n",
    "    Search files in NeoFS\n",
    "    \n",
    "    Args:\n",
    "        client: Configured HTTPX client\n",
    "        private_key: Private key bytes\n",
    "        public_key: Public key hex string\n",
    "        address: Neo address\n",
    "        container_id: Container ID to search in\n",
    "        filters: Dictionary of attribute key-value pairs to search for\n",
    "        offset: Number of objects to skip\n",
    "        limit: Maximum number of objects to return\n",
    "        \n",
    "    Returns:\n",
    "        list: List of matching object IDs\n",
    "    \"\"\"\n",
    "    # Create token for search operation\n",
    "    auth_header = {\n",
    "        'X-Bearer-Owner-Id': address,\n",
    "        'X-Bearer-Lifetime': \"10000\",\n",
    "        'X-Bearer-For-All-Users': \"false\",\n",
    "    }\n",
    "    \n",
    "    auth_content = [\n",
    "        {\n",
    "            \"name\": \"search-token\",\n",
    "            \"object\": [\n",
    "                {\n",
    "                    \"action\": \"ALLOW\",\n",
    "                    \"filters\": [],\n",
    "                    \"operation\": \"SEARCH\",\n",
    "                    \"targets\": [{\"keys\": [], \"role\": \"OTHERS\"}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    auth_resp = client.post('auth', headers=auth_header, content=json.dumps(auth_content), timeout=180).json()\n",
    "    \n",
    "    # Process and sign token\n",
    "    for t in auth_resp:\n",
    "        t[\"decoded_token\"] = b64decode(t[\"token\"])\n",
    "    for t in auth_resp:\n",
    "        t[\"signed_token\"] = sign_message(private_key, t[\"decoded_token\"]).hex()\n",
    "    for t in auth_resp:\n",
    "        assert verify_message_signature(public_key, t[\"decoded_token\"], bytes.fromhex(t[\"signed_token\"]))\n",
    "    \n",
    "    # Get the search token\n",
    "    search_token = auth_resp[0]\n",
    "    \n",
    "    # Prepare for signature\n",
    "    msg = search_token['token']\n",
    "    random_salt = os.urandom(16).hex()\n",
    "    parameter_hex_string = (random_salt + msg).encode().hex()\n",
    "    assert len(parameter_hex_string) % 2 == 0\n",
    "    length_hex = num2VarInt(len(parameter_hex_string) // 2)\n",
    "    concatenated_string = length_hex + parameter_hex_string\n",
    "    serialized_transaction = '010001f0' + concatenated_string + '0000'\n",
    "    signature = sign_message(private_key, serialized_transaction)\n",
    "    assert verify_message_signature(public_key, serialized_transaction, signature)\n",
    "    \n",
    "    # The API requires hex-encoded signature\n",
    "    signature_hex_str = signature.hex()\n",
    "    \n",
    "    # Update client headers with auth token\n",
    "    client.headers.update({\"Authorization\": f\"Bearer {search_token['token']}\"})\n",
    "    \n",
    "    # Prepare search headers\n",
    "    search_headers = {\n",
    "        'X-Bearer-Signature': signature_hex_str + random_salt, # Include random salt with signature\n",
    "        'X-Bearer-Signature-Key': public_key,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    # Prepare search filters using the correct format\n",
    "    search_filters = []\n",
    "    for key, value in filters.items():\n",
    "        search_filters.append({\n",
    "            \"key\": key,\n",
    "            \"value\": value,\n",
    "            \"match\": \"MatchStringEqual\"  # Using the correct match name from API docs\n",
    "        })\n",
    "    \n",
    "    # Construct URL with query parameters\n",
    "    search_url = f'objects/{container_id}/search?walletConnect=true&offset={offset}&limit={limit}'\n",
    "    \n",
    "    # Perform search\n",
    "    search_resp = client.post(\n",
    "        search_url,\n",
    "        headers=search_headers,\n",
    "        content=json.dumps({\n",
    "            \"filters\": search_filters\n",
    "        })\n",
    "    )\n",
    "    \n",
    "    return search_resp.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's search for files by their attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for files with specific attributes\n",
    "try:\n",
    "    # Search for our example file by filename\n",
    "    search_response = search_files(\n",
    "        httpx_client, \n",
    "        private_key, \n",
    "        public_key, \n",
    "        address, \n",
    "        container_id, \n",
    "        {\"FileName\": \"example.txt\"},\n",
    "        offset=0,\n",
    "        limit=50\n",
    "    )\n",
    "    \n",
    "    print(f\"Search results: {search_response}\")\n",
    "    \n",
    "    # You can also search by any custom attribute\n",
    "    search_response_by_desc = search_files(\n",
    "        httpx_client, \n",
    "        private_key, \n",
    "        public_key, \n",
    "        address, \n",
    "        container_id, \n",
    "        {\"Description\": \"Test file for NeoFS tutorial\"},\n",
    "        offset=0,\n",
    "        limit=50\n",
    "    )\n",
    "    \n",
    "    print(f\"Search results by description: {search_response_by_desc}\")\n",
    "except Exception as e:\n",
    "    print(f\"Search failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "NeoFS provides many other functionalities, including but not limited to:\n",
    "\n",
    "1. **Set ACL**: Configure access control lists\n",
    "2. **Create Extended ACL**: More complex access control policies\n",
    "\n",
    "These operations form the foundation of using NeoFS as a decentralized storage solution. By combining container management with these file operations, you can build robust applications that leverage the security, reliability, and decentralization benefits of NeoFS.\n",
    "Remember that all operations in NeoFS require proper authentication and signature generation, which follows the pattern we've established throughout this tutorial: create a token, sign it with your private key, and include the signature in your request."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
